{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "df = pd.read_csv('Spam SMS Collection', sep='\\t', names=['label', 'message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Separate dependent & independent features</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the independent & dependent features\n",
    "\n",
    "y = df.label.copy()\n",
    "x = df.message.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spam\n",
       "0     0\n",
       "1     0\n",
       "2     1\n",
       "3     0\n",
       "4     0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dummies of y\n",
    "\n",
    "y = pd.get_dummies(y).iloc[:, 1]\n",
    "y = pd.DataFrame(y)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Preprocess the message</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ok lar... Joking wif u oni...'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now Lets process x\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "corpus = list()\n",
    "for i in range(len(x)):\n",
    "    message = re.sub(pattern='[^a-zA-Z0-9]', repl=' ', string=x.loc[i])\n",
    "    message = message.lower()\n",
    "    message = re.sub(pattern='[\\s+]', repl=' ', string=message)\n",
    "    message = [porter.stem(word) for word in message.split() if not word in stopwords.words('english')]\n",
    "    message = ' '.join(message)\n",
    "    corpus.append(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go jurong point crazi avail bugi n great world la e buffet cine got amor wat',\n",
       " 'ok lar joke wif u oni',\n",
       " 'free entri 2 wkli comp win fa cup final tkt 21st may 2005 text fa 87121 receiv entri question std txt rate c appli 08452810075over18',\n",
       " 'u dun say earli hor u c alreadi say',\n",
       " 'nah think goe usf live around though']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Finding optimum max_features</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clssifier = MultinomialNB()\n",
    "\n",
    "scores = dict()\n",
    "for i in np.linspace(start=1000, stop=10000, num=20):\n",
    "    cv = CountVectorizer(max_features=int(i))\n",
    "    new_x = cv.fit_transform(corpus).toarray()\n",
    "    \n",
    "    score = cross_val_score(estimator=clssifier,X=new_x, y=y, cv=5, n_jobs=-1, verbose=0)\n",
    "    scores[i] = score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1000.0: 0.9833088856864529,\n",
       " 1473.6842105263158: 0.9838474853273864,\n",
       " 1947.3684210526317: 0.984744990379274,\n",
       " 2421.0526315789475: 0.9858220286448061,\n",
       " 2894.7368421052633: 0.9861810950720951,\n",
       " 3368.4210526315787: 0.9854636062828573,\n",
       " 3842.1052631578946: 0.98456610123097,\n",
       " 4315.78947368421: 0.9851043788392333,\n",
       " 4789.473684210527: 0.9845657791982998,\n",
       " 5263.157894736842: 0.9840275015900364,\n",
       " 5736.8421052631575: 0.9843864070009902,\n",
       " 6210.526315789473: 0.9838478073600566,\n",
       " 6684.210526315789: 0.9836684351627472,\n",
       " 7157.894736842105: 0.9829504633245042,\n",
       " 7631.578947368421: 0.9827710911271949,\n",
       " 8105.263157894737: 0.9827710911271949,\n",
       " 8578.947368421053: 0.9827710911271949,\n",
       " 9052.631578947368: 0.9827710911271949,\n",
       " 9526.315789473683: 0.9827710911271949,\n",
       " 10000.0: 0.9827710911271949}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>It is seen that max_feature = 2894 gives a good accuracy. So we'll consider that.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Finding Optimum ngram_range</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_scores = dict()\n",
    "\n",
    "for i in range(1,10):\n",
    "    for j in range(i, 10):\n",
    "        cv = CountVectorizer(max_features=2894, ngram_range=(i, j))\n",
    "        new_x = cv.fit_transform(corpus).toarray()\n",
    "\n",
    "        score = cross_val_score(estimator=clssifier,X=new_x, y=y, cv=5, n_jobs=-1, verbose=0)\n",
    "        ngram_scores[str(i)+','+str(j)] = score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1,1': 0.9861810950720951,\n",
       " '1,2': 0.9858218676284709,\n",
       " '1,3': 0.9851037347738929,\n",
       " '1,4': 0.9838471632947163,\n",
       " '1,5': 0.9843854409029797,\n",
       " '1,6': 0.9842059076893351,\n",
       " '1,7': 0.9840263744756905,\n",
       " '1,8': 0.9842059076893351,\n",
       " '1,9': 0.9838468412620461,\n",
       " '2,2': 0.9730791958844225,\n",
       " '2,3': 0.9673363872764892,\n",
       " '2,4': 0.9655415381890492,\n",
       " '2,5': 0.9628496670987271,\n",
       " '2,6': 0.9632084114933459,\n",
       " '2,7': 0.9623109064414586,\n",
       " '2,8': 0.9626698118524125,\n",
       " '2,9': 0.9615930956195505,\n",
       " '3,3': 0.947774673740651,\n",
       " '3,4': 0.9380826174815435,\n",
       " '3,5': 0.9348526297992932,\n",
       " '3,6': 0.9316221590680375,\n",
       " '3,7': 0.9296474547342829,\n",
       " '3,8': 0.9264174670520324,\n",
       " '3,9': 0.9264174670520324,\n",
       " '4,4': 0.9386215391551472,\n",
       " '4,5': 0.9294690486349841,\n",
       " '4,6': 0.9215720024796517,\n",
       " '4,7': 0.9208541916577436,\n",
       " '4,8': 0.9199568476221913,\n",
       " '4,9': 0.9170857653508948,\n",
       " '5,5': 0.9334166861228071,\n",
       " '5,6': 0.9271352778739402,\n",
       " '5,7': 0.9167257328255951,\n",
       " '5,8': 0.9142135559652527,\n",
       " '5,9': 0.9134955841270097,\n",
       " '6,6': 0.9292887103396639,\n",
       " '6,7': 0.9256994952137895,\n",
       " '6,8': 0.9165463606282858,\n",
       " '6,9': 0.9081116809300303,\n",
       " '7,7': 0.9258788674110988,\n",
       " '7,8': 0.9224687024498636,\n",
       " '7,9': 0.9143930891788973,\n",
       " '8,8': 0.9228274468444824,\n",
       " '8,9': 0.9240841793399941,\n",
       " '9,9': 0.9199555594915104}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>It is seen that n_gram=(1,1) gives the best result so we'll consider that</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Finding Optimum alpha</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_score = dict()\n",
    "\n",
    "for i in [0.0001, 0.0005, 0.001, 0.005, 0.009, 0.1, 0.2, 0.4, 0.6, 0.8, 1.0]:\n",
    "    cv = CountVectorizer(max_features=2894, ngram_range=(1, 1))\n",
    "    new_x = cv.fit_transform(corpus).toarray()\n",
    "    \n",
    "    classifier = MultinomialNB(alpha=i)\n",
    "    score = cross_val_score(estimator=clssifier,X=new_x, y=y, cv=5, n_jobs=-1, verbose=0)\n",
    "    alpha_score[i] = score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0001: 0.9861810950720951,\n",
       " 0.0005: 0.9861810950720951,\n",
       " 0.001: 0.9861810950720951,\n",
       " 0.005: 0.9861810950720951,\n",
       " 0.009: 0.9861810950720951,\n",
       " 0.1: 0.9861810950720951,\n",
       " 0.2: 0.9861810950720951,\n",
       " 0.4: 0.9861810950720951,\n",
       " 0.6: 0.9861810950720951,\n",
       " 0.8: 0.9861810950720951,\n",
       " 1.0: 0.9861810950720951}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>we'll consider the default alpha value</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Creating Bag-of-Words</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MultinomialNB()\n",
    "\n",
    "cv = CountVectorizer(max_features=2894, ngram_range=(1, 1))\n",
    "x_vectorized = cv.fit_transform(x).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_vectorized, y, test_size=0.3, random_state=0)\n",
    "\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9874401913875598\n",
      "[[1442    9]\n",
      " [  12  209]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1451\n",
      "           1       0.96      0.95      0.95       221\n",
      "\n",
      "    accuracy                           0.99      1672\n",
      "   macro avg       0.98      0.97      0.97      1672\n",
      "weighted avg       0.99      0.99      0.99      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Handling Imbalanced Data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam\n",
       "0       4825\n",
       "1        747\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5572,), (5572, 1))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nmber of classes before the fit Counter({'ham': 4825, 'spam': 747})\n",
      "The nmber of classes after the fit Counter({'ham': 4825, 'spam': 4825})\n"
     ]
    }
   ],
   "source": [
    "# As our data is imbalanced so we'll use Oversampling\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "os = RandomOverSampler() \n",
    "x_balanced, y_balanced = os.fit_sample(x_vectorized, df.iloc[:,0])\n",
    "\n",
    "print(f\"The nmber of classes before the fit {Counter(df.iloc[:,0])}\")\n",
    "print(f\"The nmber of classes after the fit {Counter(y_balanced)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9650, 9650)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_balanced), len(y_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_balanced, y_balanced,\n",
    "                                                    test_size=0.3, random_state=0)\n",
    "\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9789291882556131\n",
      "[[1419   19]\n",
      " [  42 1415]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      0.99      0.98      1438\n",
      "        spam       0.99      0.97      0.98      1457\n",
      "\n",
      "    accuracy                           0.98      2895\n",
      "   macro avg       0.98      0.98      0.98      2895\n",
      "weighted avg       0.98      0.98      0.98      2895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>As handling the imbalanced dataset did not improved the accuracy so we'll consider without balancing.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split\\nimport pickle'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating a pickle file for the CountVectorizer\n",
    "\n",
    "pickle.dump(cv, open('cv-transform.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split\\nimport pickle'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating a pickle file for the Multinomial Naive Bayes model\n",
    "filename = 'spam-sms-mnb-model.pkl'\n",
    "pickle.dump(classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
